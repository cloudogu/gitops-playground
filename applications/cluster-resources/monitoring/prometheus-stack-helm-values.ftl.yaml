# Note that many things are disabled here, because we want to start small, especially in airgapped envs where each image
# has to be replicated individually
defaultRules:
  rules:
    alertmanager: true
    etcd: false
    general: true
    k8s: false
    kubeApiserver: false
    kubeApiserverAvailability: false
    kubeApiserverBurnrate: false
    kubeApiserverHistogram: false
    kubeApiserverSlos: false
    kubelet: false
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: false
    kubernetesAbsent: false
    kubernetesApps: false
    kubernetesResources: false
    kubernetesStorage: false
    kubernetesSystem: false
    kubeSchedulerAlerting: false
    kubeSchedulerRecording: false
    kubeStateMetrics: false
    network: false
    node: false
    nodeExporterAlerting: false
    nodeExporterRecording: false
    prometheus: true
    prometheusOperator: true
kubeStateMetrics:
  enabled: false
nodeExporter:
  enabled: false
prometheusOperator:
  enabled: true
  admissionWebhooks:
    enabled: false
  tls:
    # Once admissionWebhooks is disabled, the operator fails with
    # MountVolume.SetUp failed for volume "tls-secret" : secret "...-kube-prometh-admission" not found
    # This can be worked around by disabling tls altogether
    enabled: false
  resources:
    limits:
      cpu: 300m
      memory: 80Mi
    requests:
      cpu: 20m
      memory: 40Mi
kubelet:
  enabled: false
kubeControllerManager:
  enabled: false
coreDns:
  enabled: false
kubeDns:
  enabled: false
kubeEtcd:
  enabled: false
kubeScheduler:
  enabled: false
kubeProxy:
  enabled: false
alertmanager:
  enabled: false
grafana:
  defaultDashboardsEnabled: false
  adminUser: admin
  adminPassword: admin
  service:
    type: NodePort
    nodePort: "9095"
<#if monitoring.grafana.host?has_content>
  ingress:
    enabled: true
    hosts: [${monitoring.grafana.host}]
</#if>
  containerSecurityContext:
    allowPrivilegeEscalation: false
  sidecar:
    securityContext:
      allowPrivilegeEscalation: false
    dashboards:
      #this needs to be added so that the label will become 'label: grafana_dashboards: "1"'
      labelValue: 1
      searchNamespace: "ALL"
    resources:
      limits:
        cpu: 100m
        memory: 130Mi
      requests:
        cpu: 35m
        memory: 65Mi
<#if mail.active??>
  notifiers:
    notifiers.yaml:
      notifiers:
      - name: mailhog
        type: email
        uid: email1
        is_default: true
        settings:
          addresses: ${monitoring.grafanaEmailTo}
          uploadImage: false

  alerting:
    contactpoints.yaml:
      apiVersion: 1
      contactPoints:
        - orgId: 1
          name: email
          is_default: true
          receivers:
          - uid: email1
            type: email
            settings:
              addresses: ${monitoring.grafanaEmailTo}
    notification-policies.yaml:
      apiVersion: 1
      policies:
        - orgId: 1
          is_default: true
          receiver: email
          routes:
          - receiver: email
          group_by: ["grafana_folder", "alertname"]
  <#if mail.smtpUser?has_content || mail.smtpPassword?has_content>
  smtp:
    # `existingSecret` is a reference to an existing secret containing the smtp configuration
    # for Grafana.
    existingSecret: "grafana-email-secret"
 </#if>
 <#if mail.smtpAddress?has_content>
  env:
    GF_SMTP_ENABLED: true
    GF_SMTP_FROM_ADDRESS: ${monitoring.grafanaEmailFrom}
    GF_SMTP_HOST: ${mail.smtpAddress}<#if mail.smtpPort?has_content>:${mail.smtpPort}</#if>
 <#else>
  env:
    GF_SMTP_ENABLED: true
    GF_SMTP_FROM_ADDRESS: ${monitoring.grafanaEmailFrom}
    GF_SMTP_HOST: mailhog.${namePrefix}monitoring.svc.cluster.local:1025
 </#if>
</#if>
  resources:
    limits:
      cpu: 1
      memory: 140Mi
    requests:
      cpu: 350m
      memory: 70Mi

prometheus:
  prometheusSpec:
    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 50m
        memory: 450Mi
    secrets:
      - prometheus-metrics-creds-scmm
      - prometheus-metrics-creds-jenkins
    additionalScrapeConfigs:
      - job_name: 'scm-manager'
        static_configs:
          - targets: [ '${scmm.host}' ]
        scheme: ${scmm.protocol}
        metrics_path: '${scmm.path}'
        basic_auth:
          username: '${namePrefix}metrics'
          password_file: '/etc/prometheus/secrets/prometheus-metrics-creds-scmm/password'
      - job_name: 'jenkins'
        static_configs:
          - targets: [ '${jenkins.host}' ]
        scheme: ${jenkins.protocol}
        metrics_path: '${jenkins.path}'
        basic_auth:
          username: '${jenkins.metricsUsername}'
          password_file: '/etc/prometheus/secrets/prometheus-metrics-creds-jenkins/password'
